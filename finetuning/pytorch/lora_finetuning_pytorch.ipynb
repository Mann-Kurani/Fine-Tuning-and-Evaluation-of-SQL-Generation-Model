{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# import torch.nn as nn\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea182c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1cc273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da983f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, padding_side=\"right\")\n",
    "if not tokenizer.pad_token:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacf68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab8f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,703,936 || all params: 1,237,518,336 || trainable%: 0.1377\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r = 8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creation(n: int) -> Dataset:\n",
    "    \"\"\"Loads and trims the text-to-SQL dataset.\"\"\"\n",
    "    dataset = load_dataset(\"gretelai/synthetic_text_to_sql\")\n",
    "    columns_to_keep = ['sql_prompt', 'sql_context', 'sql']\n",
    "\n",
    "    # Filter only required columns\n",
    "    dataset = dataset[\"train\"].remove_columns(\n",
    "        [col for col in dataset[\"train\"].column_names if col not in columns_to_keep]\n",
    "    )\n",
    "\n",
    "    return dataset.select(range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a42260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    prompts = []\n",
    "    sql_outputs = []\n",
    "\n",
    "    for sql_prompt, sql_context, sql in zip(batch[\"sql_prompt\"], batch[\"sql_context\"], batch[\"sql\"]):\n",
    "        # Build the prompt using chat format\n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that converts SQL prompts into SQL queries.\"},\n",
    "                {\"role\": \"user\", \"content\": json.dumps({\n",
    "                    \"sql_prompt\": sql_prompt,\n",
    "                    \"sql_context\": sql_context\n",
    "                })}\n",
    "            ],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "\n",
    "        # Format SQL output with EOS\n",
    "        sql_output = f'[{{\"sql\": \"{sql.strip()}\"}}]{tokenizer.eos_token}'\n",
    "        sql_outputs.append(sql_output)\n",
    "\n",
    "    # Full sequence = prompt + sql_output\n",
    "    full_texts = [p + o for p, o in zip(prompts, sql_outputs)]\n",
    "\n",
    "    # Tokenize full sequences\n",
    "    full_encodings = tokenizer(\n",
    "        full_texts,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    input_ids = full_encodings[\"input_ids\"]\n",
    "    attention_mask = full_encodings[\"attention_mask\"]\n",
    "\n",
    "    # Get prompt lengths to mask label tokens for prompts\n",
    "    prompt_lengths = [\n",
    "        len(tokenizer(p, truncation=True, max_length=512)[\"input_ids\"])\n",
    "        for p in prompts\n",
    "    ]\n",
    "\n",
    "    labels = input_ids.clone()\n",
    "    for i, prompt_len in enumerate(prompt_lengths):\n",
    "        labels[i, :prompt_len] = -100  # Mask prompt tokens\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_creation(5000).train_test_split(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[\"train\"]\n",
    "eval_df = df[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5c169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c880dc7b8ea47238ee501f9269a5cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98ecba6bf7042fb845a250c08fb90e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = train_df.map(tokenize_fn, batched=True)\n",
    "eval_df = eval_df.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4897bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7b53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# Load BLEU metric once\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Pad labels and predictions to same shape if needed\n",
    "    if logits.shape[-1] != labels.shape[-1]:\n",
    "        labels = labels[:, :logits.shape[1]]\n",
    "\n",
    "    # Predicted token IDs (greedy)\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Replace -100 in labels with pad_token_id before decoding\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    # Decode\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    print(decoded_preds)\n",
    "    print(decoded_labels)\n",
    "\n",
    "    # Clean whitespace\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "\n",
    "    # BLEU requires list-of-references format\n",
    "    result = bleu_metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=[[label] for label in decoded_labels]\n",
    "    )\n",
    "\n",
    "    # Exact Match\n",
    "    exact_match = np.mean([\n",
    "        int(pred == label)\n",
    "        for pred, label in zip(decoded_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    return {\n",
    "        \"bleu\": round(result[\"bleu\"] * 100, 2),          # BLEU score %\n",
    "        \"exact_match\": round(exact_match * 100, 2)       # EM score %\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"sql_generator_improved\",\n",
    "\n",
    "    # Basic training setup\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    gradient_checkpointing=False,\n",
    "    # # Evaluation, logging, and saving\n",
    "    # eval_strategy=\"epoch\",\n",
    "    # logging_strategy=\"steps\",\n",
    "    # logging_steps=10,\n",
    "    # save_strategy=\"epoch\",\n",
    "    # save_total_limit=2,\n",
    "    \n",
    "    eval_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=10,\n",
    "    save_steps = 50,\n",
    "    eval_steps=50,\n",
    "\n",
    "    # Learning parameters\n",
    "    learning_rate=2e-4,\n",
    "    warmup_steps=50,\n",
    "    weight_decay=0.01,\n",
    "    label_names=[\"labels\"],\n",
    "\n",
    "    # Device & precision\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    dataloader_pin_memory=False,\n",
    "\n",
    "    # Meta & checkpointing\n",
    "    seed=42,\n",
    "    report_to=\"tensorboard\",\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"exact_match\",\n",
    "    greater_is_better=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a69240",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dcbdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_df,\n",
    "    eval_dataset=eval_df,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    processing_class = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6aaeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='2970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  51/2970 10:57 < 10:53:11, 0.07 it/s, Epoch 0.17/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 39/125 04:49 < 10:55, 0.13 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 25.74 GB, other allocations: 1.10 GB, max allowed: 45.90 GB). Tried to allocate 19.57 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Personal_Code/SQL Finetune/.venv/lib/python3.11/site-packages/transformers/trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n",
      "\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n",
      "\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Personal_Code/SQL Finetune/.venv/lib/python3.11/site-packages/transformers/trainer.py:2622\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[32m   2620\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m + steps_skipped) / steps_in_epoch\n",
      "\u001b[32m   2621\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2622\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   2623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   2631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   2632\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   2633\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Personal_Code/SQL Finetune/.venv/lib/python3.11/site-packages/transformers/trainer.py:3095\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n",
      "\u001b[32m   3093\u001b[39m metrics = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[32m   3094\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_evaluate:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3095\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   3096\u001b[39m     is_new_best_metric = \u001b[38;5;28mself\u001b[39m._determine_best_metric(metrics=metrics, trial=trial)\n",
      "\u001b[32m   3098\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_strategy == SaveStrategy.BEST:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Personal_Code/SQL Finetune/.venv/lib/python3.11/site-packages/transformers/trainer.py:3044\u001b[39m, in \u001b[36mTrainer._evaluate\u001b[39m\u001b[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[39m\n",
      "\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3044\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   3045\u001b[39m     \u001b[38;5;28mself\u001b[39m._report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m.state.global_step, metrics)\n",
      "\u001b[32m   3047\u001b[39m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Personal_Code/SQL Finetune/.venv/lib/python3.11/site-packages/transformers/trainer.py:4173\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n",
      "\u001b[32m   4170\u001b[39m start_time = time.time()\n",
      "\u001b[32m   4172\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4173\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   4174\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   4175\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   4176\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n",
      "\u001b[32m   4177\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n",
      "\u001b[32m   4178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   4179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   4180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   4181\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   4183\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n",
      "\u001b[32m   4184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Personal_Code/SQL Finetune/.venv/lib/python3.11/site-packages/transformers/trainer.py:4395\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n",
      "\u001b[32m   4393\u001b[39m     logits = \u001b[38;5;28mself\u001b[39m.gather_function(logits)\n",
      "\u001b[32m   4394\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.batch_eval_metrics \u001b[38;5;129;01mor\u001b[39;00m description == \u001b[33m\"\u001b[39m\u001b[33mPrediction\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4395\u001b[39m         \u001b[43mall_preds\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   4396\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m   4397\u001b[39m     labels = \u001b[38;5;28mself\u001b[39m.gather_function(labels)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Personal_Code/SQL Finetune/.venv/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:316\u001b[39m, in \u001b[36mEvalLoopContainer.add\u001b[39m\u001b[34m(self, tensors)\u001b[39m\n",
      "\u001b[32m    314\u001b[39m     \u001b[38;5;28mself\u001b[39m.tensors = tensors \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_nested_concat \u001b[38;5;28;01melse\u001b[39;00m [tensors]\n",
      "\u001b[32m    315\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_nested_concat:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28mself\u001b[39m.tensors = \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    317\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m    318\u001b[39m     \u001b[38;5;28mself\u001b[39m.tensors.append(tensors)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Personal_Code/SQL Finetune/.venv/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:130\u001b[39m, in \u001b[36mnested_concat\u001b[39m\u001b[34m(tensors, new_tensors, padding_index)\u001b[39m\n",
      "\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index=padding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n",
      "\u001b[32m    129\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch.Tensor):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    131\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n",
      "\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n",
      "\u001b[32m    133\u001b[39m         {k: nested_concat(t, new_tensors[k], padding_index=padding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors.items()}\n",
      "\u001b[32m    134\u001b[39m     )\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Personal_Code/SQL Finetune/.venv/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:88\u001b[39m, in \u001b[36mtorch_pad_and_concatenate\u001b[39m\u001b[34m(tensor1, tensor2, padding_index)\u001b[39m\n",
      "\u001b[32m     85\u001b[39m tensor2 = atleast_1d(tensor2)\n",
      "\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1.shape) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1.shape[\u001b[32m1\u001b[39m] == tensor2.shape[\u001b[32m1\u001b[39m]:\n",
      "\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n",
      "\u001b[32m     91\u001b[39m new_shape = (tensor1.shape[\u001b[32m0\u001b[39m] + tensor2.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1.shape[\u001b[32m1\u001b[39m], tensor2.shape[\u001b[32m1\u001b[39m])) + tensor1.shape[\u001b[32m2\u001b[39m:]\n",
      "\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 25.74 GB, other allocations: 1.10 GB, max allowed: 45.90 GB). Tried to allocate 19.57 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_retries = 55\n",
    "final_model_dir = \"/Users/mann.kurani.ctr/Desktop/Personal_Code/SQL Finetune/models/finetuned_final_tinyllama\"\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        # if attempt == 0:\n",
    "        #     # Start fresh\n",
    "        #     trainer.train()\n",
    "        # else:\n",
    "        #     # Resume from checkpoint\n",
    "        #     trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.train(resume_from_checkpoint=True)\n",
    "        trainer.model.save_pretrained(final_model_dir)\n",
    "        print(\"Training complete. Model saved.\")\n",
    "        break\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"[Attempt {attempt + 1}] RuntimeError during training: {e}\")\n",
    "        print(\"Retrying after short delay...\")\n",
    "        time.sleep(10)\n",
    "        torch.mps.empty_cache()\n",
    "else:\n",
    "    print(\"Training failed after maximum retries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942cc58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab029456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef71d325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc7b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SQL Finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
