{
  "best_global_step": 900,
  "best_metric": 0.015779664739966393,
  "best_model_checkpoint": "sql_generator_improved/checkpoint-900",
  "epoch": 9.843636363636364,
  "eval_steps": 50,
  "global_step": 3050,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03232323232323232,
      "grad_norm": 0.09370500594377518,
      "learning_rate": 3.6e-05,
      "loss": 0.0308,
      "step": 10
    },
    {
      "epoch": 0.06464646464646465,
      "grad_norm": 0.09445269405841827,
      "learning_rate": 7.6e-05,
      "loss": 0.0352,
      "step": 20
    },
    {
      "epoch": 0.09696969696969697,
      "grad_norm": 0.09319240599870682,
      "learning_rate": 0.000116,
      "loss": 0.0298,
      "step": 30
    },
    {
      "epoch": 0.1292929292929293,
      "grad_norm": 0.08069128543138504,
      "learning_rate": 0.00015600000000000002,
      "loss": 0.0262,
      "step": 40
    },
    {
      "epoch": 0.16161616161616163,
      "grad_norm": 0.06716438382863998,
      "learning_rate": 0.000196,
      "loss": 0.0308,
      "step": 50
    },
    {
      "epoch": 0.16161616161616163,
      "eval_bleu": 17.56,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02545049600303173,
      "eval_runtime": 307.512,
      "eval_samples_per_second": 0.163,
      "eval_steps_per_second": 0.081,
      "step": 50
    },
    {
      "epoch": 0.19393939393939394,
      "grad_norm": 0.062294892966747284,
      "learning_rate": 0.00019940983606557376,
      "loss": 0.029,
      "step": 60
    },
    {
      "epoch": 0.22626262626262628,
      "grad_norm": 0.06113479286432266,
      "learning_rate": 0.00019875409836065576,
      "loss": 0.0257,
      "step": 70
    },
    {
      "epoch": 0.2585858585858586,
      "grad_norm": 0.059826117008924484,
      "learning_rate": 0.00019809836065573774,
      "loss": 0.0286,
      "step": 80
    },
    {
      "epoch": 0.2909090909090909,
      "grad_norm": 0.07458572089672089,
      "learning_rate": 0.00019744262295081968,
      "loss": 0.0292,
      "step": 90
    },
    {
      "epoch": 0.32323232323232326,
      "grad_norm": 0.06320244818925858,
      "learning_rate": 0.00019678688524590166,
      "loss": 0.025,
      "step": 100
    },
    {
      "epoch": 0.32323232323232326,
      "eval_bleu": 0.2,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02503393217921257,
      "eval_runtime": 354.2716,
      "eval_samples_per_second": 0.141,
      "eval_steps_per_second": 0.071,
      "step": 100
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.07096636295318604,
      "learning_rate": 0.0001961311475409836,
      "loss": 0.027,
      "step": 110
    },
    {
      "epoch": 0.3878787878787879,
      "grad_norm": 0.05390771105885506,
      "learning_rate": 0.00019547540983606558,
      "loss": 0.0275,
      "step": 120
    },
    {
      "epoch": 0.4202020202020202,
      "grad_norm": 0.07739675045013428,
      "learning_rate": 0.00019481967213114755,
      "loss": 0.0236,
      "step": 130
    },
    {
      "epoch": 0.45252525252525255,
      "grad_norm": 0.05869327113032341,
      "learning_rate": 0.0001941639344262295,
      "loss": 0.024,
      "step": 140
    },
    {
      "epoch": 0.48484848484848486,
      "grad_norm": 0.05502455309033394,
      "learning_rate": 0.00019350819672131147,
      "loss": 0.0227,
      "step": 150
    },
    {
      "epoch": 0.48484848484848486,
      "eval_bleu": 0.21,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02457786537706852,
      "eval_runtime": 204.1194,
      "eval_samples_per_second": 0.245,
      "eval_steps_per_second": 0.122,
      "step": 150
    },
    {
      "epoch": 0.5171717171717172,
      "grad_norm": 0.062498658895492554,
      "learning_rate": 0.00019285245901639347,
      "loss": 0.0259,
      "step": 160
    },
    {
      "epoch": 0.5494949494949495,
      "grad_norm": 0.05446422100067139,
      "learning_rate": 0.00019219672131147542,
      "loss": 0.0254,
      "step": 170
    },
    {
      "epoch": 0.5818181818181818,
      "grad_norm": 0.06364822387695312,
      "learning_rate": 0.0001915409836065574,
      "loss": 0.0303,
      "step": 180
    },
    {
      "epoch": 0.6141414141414141,
      "grad_norm": 0.0587216317653656,
      "learning_rate": 0.00019088524590163934,
      "loss": 0.0244,
      "step": 190
    },
    {
      "epoch": 0.6464646464646465,
      "grad_norm": 0.05967282876372337,
      "learning_rate": 0.00019022950819672132,
      "loss": 0.0261,
      "step": 200
    },
    {
      "epoch": 0.6464646464646465,
      "eval_bleu": 0.0,
      "eval_exact_match": 0.0,
      "eval_loss": 0.024757174775004387,
      "eval_runtime": 126.75,
      "eval_samples_per_second": 0.394,
      "eval_steps_per_second": 0.197,
      "step": 200
    },
    {
      "epoch": 0.6787878787878788,
      "grad_norm": 0.07720084488391876,
      "learning_rate": 0.0001895737704918033,
      "loss": 0.0287,
      "step": 210
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.0927848294377327,
      "learning_rate": 0.00018891803278688524,
      "loss": 0.0305,
      "step": 220
    },
    {
      "epoch": 0.7434343434343434,
      "grad_norm": 0.08670324087142944,
      "learning_rate": 0.0001882622950819672,
      "loss": 0.0221,
      "step": 230
    },
    {
      "epoch": 0.7757575757575758,
      "grad_norm": 0.05213835835456848,
      "learning_rate": 0.00018760655737704918,
      "loss": 0.0252,
      "step": 240
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 0.052634917199611664,
      "learning_rate": 0.00018695081967213116,
      "loss": 0.0287,
      "step": 250
    },
    {
      "epoch": 0.8080808080808081,
      "eval_bleu": 0.0,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02448344975709915,
      "eval_runtime": 150.6594,
      "eval_samples_per_second": 0.332,
      "eval_steps_per_second": 0.166,
      "step": 250
    },
    {
      "epoch": 0.8404040404040404,
      "grad_norm": 0.05109198018908501,
      "learning_rate": 0.00018629508196721313,
      "loss": 0.0257,
      "step": 260
    },
    {
      "epoch": 0.8727272727272727,
      "grad_norm": 0.05506886541843414,
      "learning_rate": 0.0001856393442622951,
      "loss": 0.0234,
      "step": 270
    },
    {
      "epoch": 0.9050505050505051,
      "grad_norm": 0.09281184524297714,
      "learning_rate": 0.00018498360655737705,
      "loss": 0.0285,
      "step": 280
    },
    {
      "epoch": 0.9373737373737374,
      "grad_norm": 0.06792087107896805,
      "learning_rate": 0.00018432786885245903,
      "loss": 0.026,
      "step": 290
    },
    {
      "epoch": 0.9696969696969697,
      "grad_norm": 0.06583452224731445,
      "learning_rate": 0.00018367213114754097,
      "loss": 0.029,
      "step": 300
    },
    {
      "epoch": 0.9696969696969697,
      "eval_bleu": 0.0,
      "eval_exact_match": 0.0,
      "eval_loss": 0.024722762405872345,
      "eval_runtime": 158.5249,
      "eval_samples_per_second": 0.315,
      "eval_steps_per_second": 0.158,
      "step": 300
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.10291185975074768,
      "learning_rate": 0.00018301639344262295,
      "loss": 0.0279,
      "step": 310
    },
    {
      "epoch": 1.0323232323232323,
      "grad_norm": 0.06705315411090851,
      "learning_rate": 0.00018236065573770492,
      "loss": 0.0228,
      "step": 320
    },
    {
      "epoch": 1.0646464646464646,
      "grad_norm": 0.05747724696993828,
      "learning_rate": 0.0001817049180327869,
      "loss": 0.021,
      "step": 330
    },
    {
      "epoch": 1.096969696969697,
      "grad_norm": 0.06113063916563988,
      "learning_rate": 0.00018104918032786887,
      "loss": 0.017,
      "step": 340
    },
    {
      "epoch": 1.1292929292929292,
      "grad_norm": 0.06404303014278412,
      "learning_rate": 0.00018039344262295084,
      "loss": 0.0234,
      "step": 350
    },
    {
      "epoch": 1.1292929292929292,
      "eval_bleu": 0.0,
      "eval_exact_match": 0.0,
      "eval_loss": 0.024952854961156845,
      "eval_runtime": 108.8578,
      "eval_samples_per_second": 0.459,
      "eval_steps_per_second": 0.23,
      "step": 350
    },
    {
      "epoch": 1.1616161616161615,
      "grad_norm": 0.061629343777894974,
      "learning_rate": 0.0001797377049180328,
      "loss": 0.021,
      "step": 360
    },
    {
      "epoch": 1.1939393939393939,
      "grad_norm": 0.047545138746500015,
      "learning_rate": 0.00017908196721311476,
      "loss": 0.0219,
      "step": 370
    },
    {
      "epoch": 1.2262626262626264,
      "grad_norm": 0.054051607847213745,
      "learning_rate": 0.00017842622950819674,
      "loss": 0.0244,
      "step": 380
    },
    {
      "epoch": 1.2585858585858585,
      "grad_norm": 0.05356968566775322,
      "learning_rate": 0.00017777049180327868,
      "loss": 0.0254,
      "step": 390
    },
    {
      "epoch": 1.290909090909091,
      "grad_norm": 0.07255344837903976,
      "learning_rate": 0.00017711475409836066,
      "loss": 0.0208,
      "step": 400
    },
    {
      "epoch": 1.290909090909091,
      "eval_bleu": 0.0,
      "eval_exact_match": 0.0,
      "eval_loss": 0.024697652086615562,
      "eval_runtime": 727.1094,
      "eval_samples_per_second": 0.069,
      "eval_steps_per_second": 0.034,
      "step": 400
    },
    {
      "epoch": 1.3232323232323233,
      "grad_norm": 0.05319817736744881,
      "learning_rate": 0.00017645901639344263,
      "loss": 0.0244,
      "step": 410
    },
    {
      "epoch": 1.3555555555555556,
      "grad_norm": 0.05764422193169594,
      "learning_rate": 0.0001758032786885246,
      "loss": 0.025,
      "step": 420
    },
    {
      "epoch": 1.387878787878788,
      "grad_norm": 0.06563548743724823,
      "learning_rate": 0.00017514754098360658,
      "loss": 0.0239,
      "step": 430
    },
    {
      "epoch": 1.4202020202020202,
      "grad_norm": 0.07544417679309845,
      "learning_rate": 0.00017449180327868853,
      "loss": 0.024,
      "step": 440
    },
    {
      "epoch": 1.4525252525252526,
      "grad_norm": 0.041610896587371826,
      "learning_rate": 0.0001738360655737705,
      "loss": 0.021,
      "step": 450
    },
    {
      "epoch": 1.4525252525252526,
      "eval_bleu": 0.0,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02436547353863716,
      "eval_runtime": 104.1454,
      "eval_samples_per_second": 0.48,
      "eval_steps_per_second": 0.24,
      "step": 450
    },
    {
      "epoch": 1.4848484848484849,
      "grad_norm": 0.05973939597606659,
      "learning_rate": 0.00017318032786885248,
      "loss": 0.0231,
      "step": 460
    },
    {
      "epoch": 1.5171717171717172,
      "grad_norm": 0.07600817829370499,
      "learning_rate": 0.00017252459016393442,
      "loss": 0.0247,
      "step": 470
    },
    {
      "epoch": 1.5494949494949495,
      "grad_norm": 0.07135234028100967,
      "learning_rate": 0.0001718688524590164,
      "loss": 0.0202,
      "step": 480
    },
    {
      "epoch": 1.5818181818181818,
      "grad_norm": 0.052577052265405655,
      "learning_rate": 0.00017121311475409837,
      "loss": 0.0219,
      "step": 490
    },
    {
      "epoch": 1.614141414141414,
      "grad_norm": 0.0626373216509819,
      "learning_rate": 0.00017055737704918034,
      "loss": 0.023,
      "step": 500
    },
    {
      "epoch": 1.614141414141414,
      "eval_bleu": 0.0,
      "eval_exact_match": 0.0,
      "eval_loss": 0.023841457441449165,
      "eval_runtime": 104.6128,
      "eval_samples_per_second": 0.478,
      "eval_steps_per_second": 0.239,
      "step": 500
    },
    {
      "epoch": 1.6464646464646466,
      "grad_norm": 0.08624238520860672,
      "learning_rate": 0.00016990163934426232,
      "loss": 0.0205,
      "step": 510
    },
    {
      "epoch": 1.6787878787878787,
      "grad_norm": 0.04792145639657974,
      "learning_rate": 0.00016924590163934426,
      "loss": 0.0221,
      "step": 520
    },
    {
      "epoch": 1.7111111111111112,
      "grad_norm": 0.04126637428998947,
      "learning_rate": 0.00016859016393442624,
      "loss": 0.0211,
      "step": 530
    },
    {
      "epoch": 1.7434343434343433,
      "grad_norm": 0.06634338200092316,
      "learning_rate": 0.0001679344262295082,
      "loss": 0.0207,
      "step": 540
    },
    {
      "epoch": 1.7757575757575759,
      "grad_norm": 0.06847618520259857,
      "learning_rate": 0.00016727868852459016,
      "loss": 0.0249,
      "step": 550
    },
    {
      "epoch": 1.7757575757575759,
      "eval_bleu": 0.0,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02431199513375759,
      "eval_runtime": 98.0916,
      "eval_samples_per_second": 0.51,
      "eval_steps_per_second": 0.255,
      "step": 550
    },
    {
      "epoch": 1.808080808080808,
      "grad_norm": 0.0734441950917244,
      "learning_rate": 0.00016662295081967213,
      "loss": 0.0216,
      "step": 560
    },
    {
      "epoch": 1.8404040404040405,
      "grad_norm": 0.0972219705581665,
      "learning_rate": 0.0001659672131147541,
      "loss": 0.0208,
      "step": 570
    },
    {
      "epoch": 1.8727272727272726,
      "grad_norm": 0.06599394977092743,
      "learning_rate": 0.00016531147540983608,
      "loss": 0.0251,
      "step": 580
    },
    {
      "epoch": 1.905050505050505,
      "grad_norm": 0.06944555789232254,
      "learning_rate": 0.00016465573770491806,
      "loss": 0.0231,
      "step": 590
    },
    {
      "epoch": 1.9373737373737374,
      "grad_norm": 0.06036335602402687,
      "learning_rate": 0.000164,
      "loss": 0.0217,
      "step": 600
    },
    {
      "epoch": 1.9373737373737374,
      "eval_bleu": 0.0,
      "eval_exact_match": 0.0,
      "eval_loss": 0.024140138179063797,
      "eval_runtime": 102.8545,
      "eval_samples_per_second": 0.486,
      "eval_steps_per_second": 0.243,
      "step": 600
    },
    {
      "epoch": 1.9696969696969697,
      "grad_norm": 0.07092442363500595,
      "learning_rate": 0.00016334426229508198,
      "loss": 0.0235,
      "step": 610
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.06917444616556168,
      "learning_rate": 0.00016268852459016395,
      "loss": 0.0236,
      "step": 620
    },
    {
      "epoch": 2.0323232323232325,
      "grad_norm": 0.06225276738405228,
      "learning_rate": 0.0001620327868852459,
      "loss": 0.0167,
      "step": 630
    },
    {
      "epoch": 2.0646464646464646,
      "grad_norm": 0.06440187245607376,
      "learning_rate": 0.00016137704918032787,
      "loss": 0.0162,
      "step": 640
    },
    {
      "epoch": 2.096969696969697,
      "grad_norm": 0.09616868197917938,
      "learning_rate": 0.00016072131147540984,
      "loss": 0.02,
      "step": 650
    },
    {
      "epoch": 2.096969696969697,
      "eval_bleu": 0.0,
      "eval_exact_match": 0.0,
      "eval_loss": 0.024863943457603455,
      "eval_runtime": 130.168,
      "eval_samples_per_second": 0.384,
      "eval_steps_per_second": 0.192,
      "step": 650
    },
    {
      "epoch": 2.1292929292929292,
      "grad_norm": 0.06804753094911575,
      "learning_rate": 0.00016006557377049182,
      "loss": 0.0185,
      "step": 660
    },
    {
      "epoch": 2.1616161616161618,
      "grad_norm": 0.06056276336312294,
      "learning_rate": 0.0001594098360655738,
      "loss": 0.0156,
      "step": 670
    },
    {
      "epoch": 2.193939393939394,
      "grad_norm": 0.0730128064751625,
      "learning_rate": 0.00015875409836065577,
      "loss": 0.0174,
      "step": 680
    },
    {
      "epoch": 2.2262626262626264,
      "grad_norm": 0.07244869321584702,
      "learning_rate": 0.0001580983606557377,
      "loss": 0.0164,
      "step": 690
    },
    {
      "epoch": 2.2585858585858585,
      "grad_norm": 0.06717949360609055,
      "learning_rate": 0.0001574426229508197,
      "loss": 0.016,
      "step": 700
    },
    {
      "epoch": 2.2585858585858585,
      "eval_bleu": 0.0,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02547992765903473,
      "eval_runtime": 110.6599,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.226,
      "step": 700
    },
    {
      "epoch": 2.290909090909091,
      "grad_norm": 0.0699925571680069,
      "learning_rate": 0.00015678688524590163,
      "loss": 0.0158,
      "step": 710
    },
    {
      "epoch": 2.323232323232323,
      "grad_norm": 0.056845296174287796,
      "learning_rate": 0.0001561311475409836,
      "loss": 0.0145,
      "step": 720
    },
    {
      "epoch": 2.3555555555555556,
      "grad_norm": 0.1883784383535385,
      "learning_rate": 0.00015547540983606558,
      "loss": 0.0175,
      "step": 730
    },
    {
      "epoch": 2.3878787878787877,
      "grad_norm": 0.09572581946849823,
      "learning_rate": 0.00015481967213114753,
      "loss": 0.0155,
      "step": 740
    },
    {
      "epoch": 2.4202020202020202,
      "grad_norm": 0.07856656610965729,
      "learning_rate": 0.00015416393442622953,
      "loss": 0.016,
      "step": 750
    },
    {
      "epoch": 2.4202020202020202,
      "eval_bleu": 21.31,
      "eval_exact_match": 0.0,
      "eval_loss": 0.019020190462470055,
      "eval_runtime": 261.4015,
      "eval_samples_per_second": 0.191,
      "eval_steps_per_second": 0.096,
      "step": 750
    },
    {
      "epoch": 2.4525252525252528,
      "grad_norm": 0.07360686361789703,
      "learning_rate": 0.0001535081967213115,
      "loss": 0.0153,
      "step": 760
    },
    {
      "epoch": 2.484848484848485,
      "grad_norm": 0.08348710834980011,
      "learning_rate": 0.00015285245901639345,
      "loss": 0.0162,
      "step": 770
    },
    {
      "epoch": 2.517171717171717,
      "grad_norm": 0.09282246977090836,
      "learning_rate": 0.00015219672131147542,
      "loss": 0.0157,
      "step": 780
    },
    {
      "epoch": 2.5494949494949495,
      "grad_norm": 0.08106206357479095,
      "learning_rate": 0.00015154098360655737,
      "loss": 0.0139,
      "step": 790
    },
    {
      "epoch": 2.581818181818182,
      "grad_norm": 0.13236556947231293,
      "learning_rate": 0.00015088524590163935,
      "loss": 0.0158,
      "step": 800
    },
    {
      "epoch": 2.581818181818182,
      "eval_bleu": 24.45,
      "eval_exact_match": 0.0,
      "eval_loss": 0.022626729682087898,
      "eval_runtime": 20.2265,
      "eval_samples_per_second": 2.472,
      "eval_steps_per_second": 1.236,
      "step": 800
    },
    {
      "epoch": 2.614141414141414,
      "grad_norm": 0.08513473719358444,
      "learning_rate": 0.00015022950819672132,
      "loss": 0.0133,
      "step": 810
    },
    {
      "epoch": 2.6464646464646466,
      "grad_norm": 0.09522419422864914,
      "learning_rate": 0.00014957377049180327,
      "loss": 0.0149,
      "step": 820
    },
    {
      "epoch": 2.6787878787878787,
      "grad_norm": 0.036243412643671036,
      "learning_rate": 0.00014891803278688524,
      "loss": 0.0151,
      "step": 830
    },
    {
      "epoch": 2.7111111111111112,
      "grad_norm": 0.05988346412777901,
      "learning_rate": 0.00014826229508196724,
      "loss": 0.0143,
      "step": 840
    },
    {
      "epoch": 2.7434343434343433,
      "grad_norm": 0.08349696546792984,
      "learning_rate": 0.0001476065573770492,
      "loss": 0.0155,
      "step": 850
    },
    {
      "epoch": 2.7434343434343433,
      "eval_bleu": 16.32,
      "eval_exact_match": 0.0,
      "eval_loss": 0.01779765821993351,
      "eval_runtime": 20.2393,
      "eval_samples_per_second": 2.47,
      "eval_steps_per_second": 1.235,
      "step": 850
    },
    {
      "epoch": 2.775757575757576,
      "grad_norm": 0.05809019133448601,
      "learning_rate": 0.00014695081967213116,
      "loss": 0.0114,
      "step": 860
    },
    {
      "epoch": 2.808080808080808,
      "grad_norm": 0.09790603816509247,
      "learning_rate": 0.00014629508196721314,
      "loss": 0.0147,
      "step": 870
    },
    {
      "epoch": 2.8404040404040405,
      "grad_norm": 0.07058251649141312,
      "learning_rate": 0.00014563934426229508,
      "loss": 0.0122,
      "step": 880
    },
    {
      "epoch": 2.8727272727272726,
      "grad_norm": 0.061238471418619156,
      "learning_rate": 0.00014498360655737706,
      "loss": 0.0145,
      "step": 890
    },
    {
      "epoch": 2.905050505050505,
      "grad_norm": 0.06097393110394478,
      "learning_rate": 0.000144327868852459,
      "loss": 0.0159,
      "step": 900
    },
    {
      "epoch": 2.905050505050505,
      "eval_bleu": 21.2,
      "eval_exact_match": 0.0,
      "eval_loss": 0.015779664739966393,
      "eval_runtime": 20.3533,
      "eval_samples_per_second": 2.457,
      "eval_steps_per_second": 1.228,
      "step": 900
    },
    {
      "epoch": 2.937373737373737,
      "grad_norm": 0.07775817066431046,
      "learning_rate": 0.00014367213114754098,
      "loss": 0.0162,
      "step": 910
    },
    {
      "epoch": 2.9696969696969697,
      "grad_norm": 0.09815497696399689,
      "learning_rate": 0.00014301639344262298,
      "loss": 0.0137,
      "step": 920
    },
    {
      "epoch": 3.0032323232323233,
      "grad_norm": 0.13394930958747864,
      "learning_rate": 0.00014236065573770492,
      "loss": 0.0153,
      "step": 930
    },
    {
      "epoch": 3.0355555555555553,
      "grad_norm": 0.07925160974264145,
      "learning_rate": 0.0001417049180327869,
      "loss": 0.0122,
      "step": 940
    },
    {
      "epoch": 3.067878787878788,
      "grad_norm": 0.09252935647964478,
      "learning_rate": 0.00014104918032786887,
      "loss": 0.0112,
      "step": 950
    },
    {
      "epoch": 3.067878787878788,
      "eval_bleu": 21.13,
      "eval_exact_match": 0.0,
      "eval_loss": 0.01601717434823513,
      "eval_runtime": 20.3371,
      "eval_samples_per_second": 2.459,
      "eval_steps_per_second": 1.229,
      "step": 950
    },
    {
      "epoch": 3.1002020202020204,
      "grad_norm": 0.08712052553892136,
      "learning_rate": 0.00014039344262295082,
      "loss": 0.0119,
      "step": 960
    },
    {
      "epoch": 3.1325252525252525,
      "grad_norm": 0.0766148567199707,
      "learning_rate": 0.0001397377049180328,
      "loss": 0.0136,
      "step": 970
    },
    {
      "epoch": 3.164848484848485,
      "grad_norm": 0.07624650001525879,
      "learning_rate": 0.00013908196721311474,
      "loss": 0.0122,
      "step": 980
    },
    {
      "epoch": 3.197171717171717,
      "grad_norm": 0.10489234328269958,
      "learning_rate": 0.00013842622950819671,
      "loss": 0.0134,
      "step": 990
    },
    {
      "epoch": 3.2294949494949496,
      "grad_norm": 0.09474737197160721,
      "learning_rate": 0.0001377704918032787,
      "loss": 0.0148,
      "step": 1000
    },
    {
      "epoch": 3.2294949494949496,
      "eval_bleu": 21.4,
      "eval_exact_match": 0.0,
      "eval_loss": 0.01676991954445839,
      "eval_runtime": 20.2865,
      "eval_samples_per_second": 2.465,
      "eval_steps_per_second": 1.232,
      "step": 1000
    },
    {
      "epoch": 3.2585858585858585,
      "grad_norm": 0.08547215163707733,
      "learning_rate": 0.00013711475409836066,
      "loss": 0.0107,
      "step": 1010
    },
    {
      "epoch": 3.290909090909091,
      "grad_norm": 0.10837892442941666,
      "learning_rate": 0.00013645901639344264,
      "loss": 0.011,
      "step": 1020
    },
    {
      "epoch": 3.323232323232323,
      "grad_norm": 0.09006736427545547,
      "learning_rate": 0.0001358032786885246,
      "loss": 0.0147,
      "step": 1030
    },
    {
      "epoch": 3.3555555555555556,
      "grad_norm": 0.060461901128292084,
      "learning_rate": 0.00013514754098360656,
      "loss": 0.0132,
      "step": 1040
    },
    {
      "epoch": 3.3878787878787877,
      "grad_norm": 0.07870109379291534,
      "learning_rate": 0.00013449180327868853,
      "loss": 0.0106,
      "step": 1050
    },
    {
      "epoch": 3.3878787878787877,
      "eval_bleu": 17.97,
      "eval_exact_match": 0.0,
      "eval_loss": 0.017297500744462013,
      "eval_runtime": 20.2419,
      "eval_samples_per_second": 2.47,
      "eval_steps_per_second": 1.235,
      "step": 1050
    },
    {
      "epoch": 3.4202020202020202,
      "grad_norm": 0.09018853306770325,
      "learning_rate": 0.0001338360655737705,
      "loss": 0.0113,
      "step": 1060
    },
    {
      "epoch": 3.4525252525252528,
      "grad_norm": 0.11036746948957443,
      "learning_rate": 0.00013318032786885245,
      "loss": 0.0114,
      "step": 1070
    },
    {
      "epoch": 3.484848484848485,
      "grad_norm": 0.10084860771894455,
      "learning_rate": 0.00013252459016393443,
      "loss": 0.0124,
      "step": 1080
    },
    {
      "epoch": 3.517171717171717,
      "grad_norm": 0.0815628245472908,
      "learning_rate": 0.0001318688524590164,
      "loss": 0.0107,
      "step": 1090
    },
    {
      "epoch": 3.5494949494949495,
      "grad_norm": 0.08057606965303421,
      "learning_rate": 0.00013121311475409837,
      "loss": 0.0124,
      "step": 1100
    },
    {
      "epoch": 3.5494949494949495,
      "eval_bleu": 17.85,
      "eval_exact_match": 0.0,
      "eval_loss": 0.016885168850421906,
      "eval_runtime": 20.1859,
      "eval_samples_per_second": 2.477,
      "eval_steps_per_second": 1.238,
      "step": 1100
    },
    {
      "epoch": 3.581818181818182,
      "grad_norm": 0.05422186106443405,
      "learning_rate": 0.00013055737704918035,
      "loss": 0.0122,
      "step": 1110
    },
    {
      "epoch": 3.614141414141414,
      "grad_norm": 0.0898129940032959,
      "learning_rate": 0.0001299016393442623,
      "loss": 0.0125,
      "step": 1120
    },
    {
      "epoch": 3.6464646464646466,
      "grad_norm": 0.09185267984867096,
      "learning_rate": 0.00012924590163934427,
      "loss": 0.0121,
      "step": 1130
    },
    {
      "epoch": 3.6787878787878787,
      "grad_norm": 0.07656937837600708,
      "learning_rate": 0.00012859016393442624,
      "loss": 0.0144,
      "step": 1140
    },
    {
      "epoch": 3.7111111111111112,
      "grad_norm": 0.05879586189985275,
      "learning_rate": 0.0001279344262295082,
      "loss": 0.0139,
      "step": 1150
    },
    {
      "epoch": 3.7111111111111112,
      "eval_bleu": 17.79,
      "eval_exact_match": 0.0,
      "eval_loss": 0.01656322553753853,
      "eval_runtime": 20.1074,
      "eval_samples_per_second": 2.487,
      "eval_steps_per_second": 1.243,
      "step": 1150
    },
    {
      "epoch": 3.7434343434343433,
      "grad_norm": 0.07015460729598999,
      "learning_rate": 0.00012727868852459016,
      "loss": 0.0112,
      "step": 1160
    },
    {
      "epoch": 3.775757575757576,
      "grad_norm": 0.08456701785326004,
      "learning_rate": 0.00012662295081967214,
      "loss": 0.0126,
      "step": 1170
    },
    {
      "epoch": 3.808080808080808,
      "grad_norm": 0.07749579846858978,
      "learning_rate": 0.0001259672131147541,
      "loss": 0.0147,
      "step": 1180
    },
    {
      "epoch": 3.8404040404040405,
      "grad_norm": 0.054057154804468155,
      "learning_rate": 0.00012531147540983608,
      "loss": 0.0122,
      "step": 1190
    },
    {
      "epoch": 3.8727272727272726,
      "grad_norm": 0.062403690069913864,
      "learning_rate": 0.00012465573770491803,
      "loss": 0.014,
      "step": 1200
    },
    {
      "epoch": 3.8727272727272726,
      "eval_bleu": 17.79,
      "eval_exact_match": 0.0,
      "eval_loss": 0.017047278583049774,
      "eval_runtime": 20.2128,
      "eval_samples_per_second": 2.474,
      "eval_steps_per_second": 1.237,
      "step": 1200
    },
    {
      "epoch": 3.905050505050505,
      "grad_norm": 0.06725535541772842,
      "learning_rate": 0.000124,
      "loss": 0.0141,
      "step": 1210
    },
    {
      "epoch": 3.937373737373737,
      "grad_norm": 0.09020626544952393,
      "learning_rate": 0.00012334426229508198,
      "loss": 0.014,
      "step": 1220
    },
    {
      "epoch": 3.9696969696969697,
      "grad_norm": 0.08162152022123337,
      "learning_rate": 0.00012268852459016393,
      "loss": 0.0132,
      "step": 1230
    },
    {
      "epoch": 4.003232323232323,
      "grad_norm": 0.19938582181930542,
      "learning_rate": 0.00012203278688524591,
      "loss": 0.0121,
      "step": 1240
    },
    {
      "epoch": 4.035555555555556,
      "grad_norm": 0.041072409600019455,
      "learning_rate": 0.00012137704918032789,
      "loss": 0.0096,
      "step": 1250
    },
    {
      "epoch": 4.035555555555556,
      "eval_bleu": 17.91,
      "eval_exact_match": 0.0,
      "eval_loss": 0.017964882776141167,
      "eval_runtime": 20.2367,
      "eval_samples_per_second": 2.471,
      "eval_steps_per_second": 1.235,
      "step": 1250
    },
    {
      "epoch": 4.067878787878788,
      "grad_norm": 0.07680422067642212,
      "learning_rate": 0.00012072131147540983,
      "loss": 0.0082,
      "step": 1260
    },
    {
      "epoch": 4.10020202020202,
      "grad_norm": 0.0856962576508522,
      "learning_rate": 0.00012006557377049181,
      "loss": 0.0088,
      "step": 1270
    },
    {
      "epoch": 4.1325252525252525,
      "grad_norm": 0.12702031433582306,
      "learning_rate": 0.00011940983606557377,
      "loss": 0.0082,
      "step": 1280
    },
    {
      "epoch": 4.164848484848485,
      "grad_norm": 0.05729159712791443,
      "learning_rate": 0.00011875409836065574,
      "loss": 0.0088,
      "step": 1290
    },
    {
      "epoch": 4.1971717171717176,
      "grad_norm": 0.12095571309328079,
      "learning_rate": 0.00011809836065573772,
      "loss": 0.0091,
      "step": 1300
    },
    {
      "epoch": 4.1971717171717176,
      "eval_bleu": 17.91,
      "eval_exact_match": 0.0,
      "eval_loss": 0.018500303849577904,
      "eval_runtime": 20.1864,
      "eval_samples_per_second": 2.477,
      "eval_steps_per_second": 1.238,
      "step": 1300
    },
    {
      "epoch": 4.229494949494949,
      "grad_norm": 0.07306312024593353,
      "learning_rate": 0.00011744262295081966,
      "loss": 0.009,
      "step": 1310
    },
    {
      "epoch": 4.261818181818182,
      "grad_norm": 0.08544741570949554,
      "learning_rate": 0.00011678688524590165,
      "loss": 0.0093,
      "step": 1320
    },
    {
      "epoch": 4.294141414141414,
      "grad_norm": 0.1010277271270752,
      "learning_rate": 0.00011613114754098362,
      "loss": 0.0103,
      "step": 1330
    },
    {
      "epoch": 4.326464646464647,
      "grad_norm": 0.07699994742870331,
      "learning_rate": 0.00011547540983606557,
      "loss": 0.009,
      "step": 1340
    },
    {
      "epoch": 4.358787878787878,
      "grad_norm": 0.09133646637201309,
      "learning_rate": 0.00011481967213114755,
      "loss": 0.0092,
      "step": 1350
    },
    {
      "epoch": 4.358787878787878,
      "eval_bleu": 18.49,
      "eval_exact_match": 0.0,
      "eval_loss": 0.018658652901649475,
      "eval_runtime": 20.1119,
      "eval_samples_per_second": 2.486,
      "eval_steps_per_second": 1.243,
      "step": 1350
    },
    {
      "epoch": 4.391111111111111,
      "grad_norm": 0.1084936335682869,
      "learning_rate": 0.00011416393442622952,
      "loss": 0.0085,
      "step": 1360
    },
    {
      "epoch": 4.4234343434343435,
      "grad_norm": 0.08576205372810364,
      "learning_rate": 0.00011350819672131148,
      "loss": 0.0091,
      "step": 1370
    },
    {
      "epoch": 4.455757575757576,
      "grad_norm": 0.10800857096910477,
      "learning_rate": 0.00011285245901639345,
      "loss": 0.0096,
      "step": 1380
    },
    {
      "epoch": 4.488080808080808,
      "grad_norm": 0.11231466382741928,
      "learning_rate": 0.0001121967213114754,
      "loss": 0.01,
      "step": 1390
    },
    {
      "epoch": 4.52040404040404,
      "grad_norm": 0.08411936461925507,
      "learning_rate": 0.00011154098360655737,
      "loss": 0.0075,
      "step": 1400
    },
    {
      "epoch": 4.52040404040404,
      "eval_bleu": 18.49,
      "eval_exact_match": 0.0,
      "eval_loss": 0.01909690909087658,
      "eval_runtime": 20.154,
      "eval_samples_per_second": 2.481,
      "eval_steps_per_second": 1.24,
      "step": 1400
    },
    {
      "epoch": 4.552727272727273,
      "grad_norm": 0.08481896668672562,
      "learning_rate": 0.00011088524590163936,
      "loss": 0.0086,
      "step": 1410
    },
    {
      "epoch": 4.585050505050505,
      "grad_norm": 0.12100139260292053,
      "learning_rate": 0.00011022950819672131,
      "loss": 0.0098,
      "step": 1420
    },
    {
      "epoch": 4.617373737373738,
      "grad_norm": 0.08637285232543945,
      "learning_rate": 0.00010957377049180328,
      "loss": 0.0089,
      "step": 1430
    },
    {
      "epoch": 4.649696969696969,
      "grad_norm": 0.0964336171746254,
      "learning_rate": 0.00010891803278688526,
      "loss": 0.0103,
      "step": 1440
    },
    {
      "epoch": 4.682020202020202,
      "grad_norm": 0.07980123907327652,
      "learning_rate": 0.00010826229508196722,
      "loss": 0.0085,
      "step": 1450
    },
    {
      "epoch": 4.682020202020202,
      "eval_bleu": 18.49,
      "eval_exact_match": 0.0,
      "eval_loss": 0.019848616793751717,
      "eval_runtime": 20.0778,
      "eval_samples_per_second": 2.49,
      "eval_steps_per_second": 1.245,
      "step": 1450
    },
    {
      "epoch": 4.7143434343434345,
      "grad_norm": 0.09735932946205139,
      "learning_rate": 0.00010760655737704919,
      "loss": 0.0098,
      "step": 1460
    },
    {
      "epoch": 4.746666666666667,
      "grad_norm": 0.15108776092529297,
      "learning_rate": 0.00010695081967213114,
      "loss": 0.0113,
      "step": 1470
    },
    {
      "epoch": 4.778989898989899,
      "grad_norm": 0.060047976672649384,
      "learning_rate": 0.00010629508196721311,
      "loss": 0.0109,
      "step": 1480
    },
    {
      "epoch": 4.811313131313131,
      "grad_norm": 0.10267225652933121,
      "learning_rate": 0.00010563934426229509,
      "loss": 0.0109,
      "step": 1490
    },
    {
      "epoch": 4.843636363636364,
      "grad_norm": 0.061922166496515274,
      "learning_rate": 0.00010498360655737705,
      "loss": 0.0106,
      "step": 1500
    },
    {
      "epoch": 4.843636363636364,
      "eval_bleu": 18.61,
      "eval_exact_match": 0.0,
      "eval_loss": 0.01880890130996704,
      "eval_runtime": 20.18,
      "eval_samples_per_second": 2.478,
      "eval_steps_per_second": 1.239,
      "step": 1500
    },
    {
      "epoch": 4.875959595959596,
      "grad_norm": 0.07641275972127914,
      "learning_rate": 0.00010432786885245902,
      "loss": 0.0099,
      "step": 1510
    },
    {
      "epoch": 4.908282828282828,
      "grad_norm": 0.0664277896285057,
      "learning_rate": 0.000103672131147541,
      "loss": 0.007,
      "step": 1520
    },
    {
      "epoch": 4.9406060606060604,
      "grad_norm": 0.12109701335430145,
      "learning_rate": 0.00010301639344262295,
      "loss": 0.0108,
      "step": 1530
    },
    {
      "epoch": 4.972929292929293,
      "grad_norm": 0.08479680120944977,
      "learning_rate": 0.00010236065573770493,
      "loss": 0.0085,
      "step": 1540
    },
    {
      "epoch": 5.003232323232323,
      "grad_norm": 0.06304994225502014,
      "learning_rate": 0.0001017049180327869,
      "loss": 0.0104,
      "step": 1550
    },
    {
      "epoch": 5.003232323232323,
      "eval_bleu": 18.55,
      "eval_exact_match": 0.0,
      "eval_loss": 0.019478455185890198,
      "eval_runtime": 20.1691,
      "eval_samples_per_second": 2.479,
      "eval_steps_per_second": 1.24,
      "step": 1550
    },
    {
      "epoch": 5.035555555555556,
      "grad_norm": 0.17036963999271393,
      "learning_rate": 0.00010104918032786885,
      "loss": 0.0078,
      "step": 1560
    },
    {
      "epoch": 5.067878787878788,
      "grad_norm": 0.06434120982885361,
      "learning_rate": 0.00010039344262295082,
      "loss": 0.0062,
      "step": 1570
    },
    {
      "epoch": 5.10020202020202,
      "grad_norm": 0.1333373486995697,
      "learning_rate": 9.97377049180328e-05,
      "loss": 0.0059,
      "step": 1580
    },
    {
      "epoch": 5.1325252525252525,
      "grad_norm": 0.05977558344602585,
      "learning_rate": 9.908196721311476e-05,
      "loss": 0.0058,
      "step": 1590
    },
    {
      "epoch": 5.164848484848485,
      "grad_norm": 0.06876227259635925,
      "learning_rate": 9.842622950819672e-05,
      "loss": 0.0067,
      "step": 1600
    },
    {
      "epoch": 5.164848484848485,
      "eval_bleu": 17.79,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02087910659611225,
      "eval_runtime": 20.2071,
      "eval_samples_per_second": 2.474,
      "eval_steps_per_second": 1.237,
      "step": 1600
    },
    {
      "epoch": 5.1971717171717176,
      "grad_norm": 0.08956777304410934,
      "learning_rate": 9.777049180327869e-05,
      "loss": 0.0076,
      "step": 1610
    },
    {
      "epoch": 5.229494949494949,
      "grad_norm": 0.06724144518375397,
      "learning_rate": 9.711475409836067e-05,
      "loss": 0.0054,
      "step": 1620
    },
    {
      "epoch": 5.261818181818182,
      "grad_norm": 0.0930294394493103,
      "learning_rate": 9.645901639344263e-05,
      "loss": 0.0075,
      "step": 1630
    },
    {
      "epoch": 5.294141414141414,
      "grad_norm": 0.07112875580787659,
      "learning_rate": 9.580327868852459e-05,
      "loss": 0.0059,
      "step": 1640
    },
    {
      "epoch": 5.326464646464647,
      "grad_norm": 0.09569711983203888,
      "learning_rate": 9.514754098360656e-05,
      "loss": 0.0044,
      "step": 1650
    },
    {
      "epoch": 5.326464646464647,
      "eval_bleu": 18.09,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02118566818535328,
      "eval_runtime": 20.1899,
      "eval_samples_per_second": 2.476,
      "eval_steps_per_second": 1.238,
      "step": 1650
    },
    {
      "epoch": 5.358787878787878,
      "grad_norm": 0.06414701044559479,
      "learning_rate": 9.449180327868853e-05,
      "loss": 0.0071,
      "step": 1660
    },
    {
      "epoch": 5.391111111111111,
      "grad_norm": 0.10684450715780258,
      "learning_rate": 9.38360655737705e-05,
      "loss": 0.0057,
      "step": 1670
    },
    {
      "epoch": 5.4234343434343435,
      "grad_norm": 0.08458486199378967,
      "learning_rate": 9.318032786885247e-05,
      "loss": 0.0061,
      "step": 1680
    },
    {
      "epoch": 5.455757575757576,
      "grad_norm": 0.08150400966405869,
      "learning_rate": 9.252459016393443e-05,
      "loss": 0.0062,
      "step": 1690
    },
    {
      "epoch": 5.488080808080808,
      "grad_norm": 0.05568616837263107,
      "learning_rate": 9.18688524590164e-05,
      "loss": 0.0047,
      "step": 1700
    },
    {
      "epoch": 5.488080808080808,
      "eval_bleu": 17.91,
      "eval_exact_match": 0.0,
      "eval_loss": 0.020932281389832497,
      "eval_runtime": 20.2499,
      "eval_samples_per_second": 2.469,
      "eval_steps_per_second": 1.235,
      "step": 1700
    },
    {
      "epoch": 5.52040404040404,
      "grad_norm": 0.06011586636304855,
      "learning_rate": 9.121311475409836e-05,
      "loss": 0.006,
      "step": 1710
    },
    {
      "epoch": 5.552727272727273,
      "grad_norm": 0.09133834391832352,
      "learning_rate": 9.055737704918034e-05,
      "loss": 0.0072,
      "step": 1720
    },
    {
      "epoch": 5.585050505050505,
      "grad_norm": 0.07936835289001465,
      "learning_rate": 8.99016393442623e-05,
      "loss": 0.0058,
      "step": 1730
    },
    {
      "epoch": 5.617373737373738,
      "grad_norm": 0.10488025099039078,
      "learning_rate": 8.924590163934426e-05,
      "loss": 0.0064,
      "step": 1740
    },
    {
      "epoch": 5.649696969696969,
      "grad_norm": 0.12442632764577866,
      "learning_rate": 8.859016393442623e-05,
      "loss": 0.0067,
      "step": 1750
    },
    {
      "epoch": 5.649696969696969,
      "eval_bleu": 18.61,
      "eval_exact_match": 0.0,
      "eval_loss": 0.020086826756596565,
      "eval_runtime": 20.2235,
      "eval_samples_per_second": 2.472,
      "eval_steps_per_second": 1.236,
      "step": 1750
    },
    {
      "epoch": 5.682020202020202,
      "grad_norm": 0.08630231022834778,
      "learning_rate": 8.79344262295082e-05,
      "loss": 0.0065,
      "step": 1760
    },
    {
      "epoch": 5.7143434343434345,
      "grad_norm": 0.10745573043823242,
      "learning_rate": 8.727868852459017e-05,
      "loss": 0.0053,
      "step": 1770
    },
    {
      "epoch": 5.746666666666667,
      "grad_norm": 0.0807754173874855,
      "learning_rate": 8.662295081967213e-05,
      "loss": 0.006,
      "step": 1780
    },
    {
      "epoch": 5.778989898989899,
      "grad_norm": 0.10084487497806549,
      "learning_rate": 8.59672131147541e-05,
      "loss": 0.0065,
      "step": 1790
    },
    {
      "epoch": 5.811313131313131,
      "grad_norm": 0.12501205503940582,
      "learning_rate": 8.531147540983607e-05,
      "loss": 0.0055,
      "step": 1800
    },
    {
      "epoch": 5.811313131313131,
      "eval_bleu": 18.61,
      "eval_exact_match": 0.0,
      "eval_loss": 0.021594533696770668,
      "eval_runtime": 20.2022,
      "eval_samples_per_second": 2.475,
      "eval_steps_per_second": 1.237,
      "step": 1800
    },
    {
      "epoch": 5.843636363636364,
      "grad_norm": 0.09084612876176834,
      "learning_rate": 8.465573770491803e-05,
      "loss": 0.0069,
      "step": 1810
    },
    {
      "epoch": 5.875959595959596,
      "grad_norm": 0.07728321105241776,
      "learning_rate": 8.4e-05,
      "loss": 0.0065,
      "step": 1820
    },
    {
      "epoch": 5.908282828282828,
      "grad_norm": 0.19964273273944855,
      "learning_rate": 8.334426229508198e-05,
      "loss": 0.006,
      "step": 1830
    },
    {
      "epoch": 5.9406060606060604,
      "grad_norm": 0.07149563729763031,
      "learning_rate": 8.268852459016394e-05,
      "loss": 0.007,
      "step": 1840
    },
    {
      "epoch": 5.972929292929293,
      "grad_norm": 0.06230585277080536,
      "learning_rate": 8.20327868852459e-05,
      "loss": 0.0075,
      "step": 1850
    },
    {
      "epoch": 5.972929292929293,
      "eval_bleu": 17.91,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02103397622704506,
      "eval_runtime": 20.2051,
      "eval_samples_per_second": 2.475,
      "eval_steps_per_second": 1.237,
      "step": 1850
    },
    {
      "epoch": 6.003232323232323,
      "grad_norm": 0.056896861642599106,
      "learning_rate": 8.137704918032786e-05,
      "loss": 0.0048,
      "step": 1860
    },
    {
      "epoch": 6.035555555555556,
      "grad_norm": 0.053771089762449265,
      "learning_rate": 8.072131147540984e-05,
      "loss": 0.004,
      "step": 1870
    },
    {
      "epoch": 6.067878787878788,
      "grad_norm": 0.05988483130931854,
      "learning_rate": 8.006557377049181e-05,
      "loss": 0.0039,
      "step": 1880
    },
    {
      "epoch": 6.10020202020202,
      "grad_norm": 0.054328467696905136,
      "learning_rate": 7.940983606557377e-05,
      "loss": 0.005,
      "step": 1890
    },
    {
      "epoch": 6.1325252525252525,
      "grad_norm": 0.0819060206413269,
      "learning_rate": 7.875409836065573e-05,
      "loss": 0.0046,
      "step": 1900
    },
    {
      "epoch": 6.1325252525252525,
      "eval_bleu": 18.61,
      "eval_exact_match": 0.0,
      "eval_loss": 0.022869501262903214,
      "eval_runtime": 20.12,
      "eval_samples_per_second": 2.485,
      "eval_steps_per_second": 1.243,
      "step": 1900
    },
    {
      "epoch": 6.164848484848485,
      "grad_norm": 0.0733964666724205,
      "learning_rate": 7.80983606557377e-05,
      "loss": 0.0037,
      "step": 1910
    },
    {
      "epoch": 6.1971717171717176,
      "grad_norm": 0.05014834925532341,
      "learning_rate": 7.744262295081968e-05,
      "loss": 0.0033,
      "step": 1920
    },
    {
      "epoch": 6.229494949494949,
      "grad_norm": 0.07843266427516937,
      "learning_rate": 7.678688524590164e-05,
      "loss": 0.0039,
      "step": 1930
    },
    {
      "epoch": 6.261818181818182,
      "grad_norm": 0.06413353979587555,
      "learning_rate": 7.61311475409836e-05,
      "loss": 0.0041,
      "step": 1940
    },
    {
      "epoch": 6.294141414141414,
      "grad_norm": 0.150918647646904,
      "learning_rate": 7.547540983606558e-05,
      "loss": 0.0042,
      "step": 1950
    },
    {
      "epoch": 6.294141414141414,
      "eval_bleu": 18.49,
      "eval_exact_match": 0.0,
      "eval_loss": 0.022684888914227486,
      "eval_runtime": 20.1148,
      "eval_samples_per_second": 2.486,
      "eval_steps_per_second": 1.243,
      "step": 1950
    },
    {
      "epoch": 6.326464646464647,
      "grad_norm": 0.21594999730587006,
      "learning_rate": 7.481967213114755e-05,
      "loss": 0.0036,
      "step": 1960
    },
    {
      "epoch": 6.358787878787878,
      "grad_norm": 0.0550878643989563,
      "learning_rate": 7.416393442622951e-05,
      "loss": 0.0037,
      "step": 1970
    },
    {
      "epoch": 6.391111111111111,
      "grad_norm": 0.07173001766204834,
      "learning_rate": 7.350819672131148e-05,
      "loss": 0.0035,
      "step": 1980
    },
    {
      "epoch": 6.4234343434343435,
      "grad_norm": 0.047323185950517654,
      "learning_rate": 7.285245901639344e-05,
      "loss": 0.004,
      "step": 1990
    },
    {
      "epoch": 6.455757575757576,
      "grad_norm": 0.06814001500606537,
      "learning_rate": 7.219672131147542e-05,
      "loss": 0.0046,
      "step": 2000
    },
    {
      "epoch": 6.455757575757576,
      "eval_bleu": 18.37,
      "eval_exact_match": 0.0,
      "eval_loss": 0.024196725338697433,
      "eval_runtime": 20.16,
      "eval_samples_per_second": 2.48,
      "eval_steps_per_second": 1.24,
      "step": 2000
    },
    {
      "epoch": 6.488080808080808,
      "grad_norm": 0.07673663645982742,
      "learning_rate": 7.154098360655738e-05,
      "loss": 0.0049,
      "step": 2010
    },
    {
      "epoch": 6.52040404040404,
      "grad_norm": 0.04219350218772888,
      "learning_rate": 7.088524590163935e-05,
      "loss": 0.0033,
      "step": 2020
    },
    {
      "epoch": 6.552727272727273,
      "grad_norm": 0.08775721490383148,
      "learning_rate": 7.022950819672131e-05,
      "loss": 0.0038,
      "step": 2030
    },
    {
      "epoch": 6.585050505050505,
      "grad_norm": 0.07836153358221054,
      "learning_rate": 6.957377049180329e-05,
      "loss": 0.0043,
      "step": 2040
    },
    {
      "epoch": 6.617373737373738,
      "grad_norm": 0.06880064308643341,
      "learning_rate": 6.891803278688525e-05,
      "loss": 0.0043,
      "step": 2050
    },
    {
      "epoch": 6.617373737373738,
      "eval_bleu": 18.61,
      "eval_exact_match": 0.0,
      "eval_loss": 0.023250332102179527,
      "eval_runtime": 20.1944,
      "eval_samples_per_second": 2.476,
      "eval_steps_per_second": 1.238,
      "step": 2050
    },
    {
      "epoch": 6.649696969696969,
      "grad_norm": 0.14247392117977142,
      "learning_rate": 6.826229508196722e-05,
      "loss": 0.0041,
      "step": 2060
    },
    {
      "epoch": 6.682020202020202,
      "grad_norm": 0.0754663273692131,
      "learning_rate": 6.760655737704918e-05,
      "loss": 0.0045,
      "step": 2070
    },
    {
      "epoch": 6.7143434343434345,
      "grad_norm": 0.08946675807237625,
      "learning_rate": 6.695081967213116e-05,
      "loss": 0.0047,
      "step": 2080
    },
    {
      "epoch": 6.746666666666667,
      "grad_norm": 0.0824916884303093,
      "learning_rate": 6.629508196721312e-05,
      "loss": 0.0047,
      "step": 2090
    },
    {
      "epoch": 6.778989898989899,
      "grad_norm": 0.058517906814813614,
      "learning_rate": 6.563934426229509e-05,
      "loss": 0.0034,
      "step": 2100
    },
    {
      "epoch": 6.778989898989899,
      "eval_bleu": 18.61,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02459855005145073,
      "eval_runtime": 20.1397,
      "eval_samples_per_second": 2.483,
      "eval_steps_per_second": 1.241,
      "step": 2100
    },
    {
      "epoch": 6.811313131313131,
      "grad_norm": 0.08823354542255402,
      "learning_rate": 6.498360655737705e-05,
      "loss": 0.0045,
      "step": 2110
    },
    {
      "epoch": 6.843636363636364,
      "grad_norm": 0.09339017421007156,
      "learning_rate": 6.432786885245901e-05,
      "loss": 0.0046,
      "step": 2120
    },
    {
      "epoch": 6.875959595959596,
      "grad_norm": 0.0687389150261879,
      "learning_rate": 6.3672131147541e-05,
      "loss": 0.0035,
      "step": 2130
    },
    {
      "epoch": 6.908282828282828,
      "grad_norm": 0.18411226570606232,
      "learning_rate": 6.301639344262296e-05,
      "loss": 0.0044,
      "step": 2140
    },
    {
      "epoch": 6.9406060606060604,
      "grad_norm": 0.08755433559417725,
      "learning_rate": 6.236065573770492e-05,
      "loss": 0.0044,
      "step": 2150
    },
    {
      "epoch": 6.9406060606060604,
      "eval_bleu": 18.74,
      "eval_exact_match": 0.0,
      "eval_loss": 0.023871464654803276,
      "eval_runtime": 20.1064,
      "eval_samples_per_second": 2.487,
      "eval_steps_per_second": 1.243,
      "step": 2150
    },
    {
      "epoch": 6.972929292929293,
      "grad_norm": 0.0675606057047844,
      "learning_rate": 6.170491803278688e-05,
      "loss": 0.0042,
      "step": 2160
    },
    {
      "epoch": 7.003232323232323,
      "grad_norm": 0.05208253487944603,
      "learning_rate": 6.104918032786887e-05,
      "loss": 0.0044,
      "step": 2170
    },
    {
      "epoch": 7.035555555555556,
      "grad_norm": 0.05082492530345917,
      "learning_rate": 6.039344262295083e-05,
      "loss": 0.0022,
      "step": 2180
    },
    {
      "epoch": 7.067878787878788,
      "grad_norm": 0.06851726025342941,
      "learning_rate": 5.973770491803279e-05,
      "loss": 0.0026,
      "step": 2190
    },
    {
      "epoch": 7.10020202020202,
      "grad_norm": 0.09748952835798264,
      "learning_rate": 5.9081967213114754e-05,
      "loss": 0.0029,
      "step": 2200
    },
    {
      "epoch": 7.10020202020202,
      "eval_bleu": 18.68,
      "eval_exact_match": 0.0,
      "eval_loss": 0.025970766320824623,
      "eval_runtime": 20.0826,
      "eval_samples_per_second": 2.49,
      "eval_steps_per_second": 1.245,
      "step": 2200
    },
    {
      "epoch": 7.1325252525252525,
      "grad_norm": 0.06289352476596832,
      "learning_rate": 5.842622950819673e-05,
      "loss": 0.003,
      "step": 2210
    },
    {
      "epoch": 7.164848484848485,
      "grad_norm": 0.04957255348563194,
      "learning_rate": 5.7770491803278695e-05,
      "loss": 0.0022,
      "step": 2220
    },
    {
      "epoch": 7.1971717171717176,
      "grad_norm": 0.05125809833407402,
      "learning_rate": 5.7114754098360656e-05,
      "loss": 0.0023,
      "step": 2230
    },
    {
      "epoch": 7.229494949494949,
      "grad_norm": 0.058259885758161545,
      "learning_rate": 5.645901639344262e-05,
      "loss": 0.0027,
      "step": 2240
    },
    {
      "epoch": 7.261818181818182,
      "grad_norm": 0.030670972540974617,
      "learning_rate": 5.58032786885246e-05,
      "loss": 0.0026,
      "step": 2250
    },
    {
      "epoch": 7.261818181818182,
      "eval_bleu": 17.06,
      "eval_exact_match": 0.0,
      "eval_loss": 0.0266905315220356,
      "eval_runtime": 20.1669,
      "eval_samples_per_second": 2.479,
      "eval_steps_per_second": 1.24,
      "step": 2250
    },
    {
      "epoch": 7.294141414141414,
      "grad_norm": 0.04195970669388771,
      "learning_rate": 5.514754098360656e-05,
      "loss": 0.0024,
      "step": 2260
    },
    {
      "epoch": 7.326464646464647,
      "grad_norm": 0.018356988206505775,
      "learning_rate": 5.4491803278688524e-05,
      "loss": 0.0021,
      "step": 2270
    },
    {
      "epoch": 7.358787878787878,
      "grad_norm": 0.037780001759529114,
      "learning_rate": 5.383606557377049e-05,
      "loss": 0.0024,
      "step": 2280
    },
    {
      "epoch": 7.391111111111111,
      "grad_norm": 0.03512142226099968,
      "learning_rate": 5.3180327868852465e-05,
      "loss": 0.0026,
      "step": 2290
    },
    {
      "epoch": 7.4234343434343435,
      "grad_norm": 0.052130747586488724,
      "learning_rate": 5.2524590163934426e-05,
      "loss": 0.0025,
      "step": 2300
    },
    {
      "epoch": 7.4234343434343435,
      "eval_bleu": 17.12,
      "eval_exact_match": 0.0,
      "eval_loss": 0.027252068743109703,
      "eval_runtime": 20.0632,
      "eval_samples_per_second": 2.492,
      "eval_steps_per_second": 1.246,
      "step": 2300
    },
    {
      "epoch": 7.455757575757576,
      "grad_norm": 0.053339000791311264,
      "learning_rate": 5.186885245901639e-05,
      "loss": 0.0023,
      "step": 2310
    },
    {
      "epoch": 7.488080808080808,
      "grad_norm": 0.10858669131994247,
      "learning_rate": 5.121311475409837e-05,
      "loss": 0.0032,
      "step": 2320
    },
    {
      "epoch": 7.52040404040404,
      "grad_norm": 0.02426203526556492,
      "learning_rate": 5.0557377049180334e-05,
      "loss": 0.0026,
      "step": 2330
    },
    {
      "epoch": 7.552727272727273,
      "grad_norm": 0.1795114129781723,
      "learning_rate": 4.9901639344262294e-05,
      "loss": 0.0029,
      "step": 2340
    },
    {
      "epoch": 7.585050505050505,
      "grad_norm": 0.06043071299791336,
      "learning_rate": 4.924590163934427e-05,
      "loss": 0.0025,
      "step": 2350
    },
    {
      "epoch": 7.585050505050505,
      "eval_bleu": 17.85,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02626866288483143,
      "eval_runtime": 20.2081,
      "eval_samples_per_second": 2.474,
      "eval_steps_per_second": 1.237,
      "step": 2350
    },
    {
      "epoch": 7.617373737373738,
      "grad_norm": 0.058328043669462204,
      "learning_rate": 4.859016393442623e-05,
      "loss": 0.0031,
      "step": 2360
    },
    {
      "epoch": 7.649696969696969,
      "grad_norm": 0.04254985973238945,
      "learning_rate": 4.79344262295082e-05,
      "loss": 0.0027,
      "step": 2370
    },
    {
      "epoch": 7.682020202020202,
      "grad_norm": 0.038292862474918365,
      "learning_rate": 4.727868852459016e-05,
      "loss": 0.0026,
      "step": 2380
    },
    {
      "epoch": 7.7143434343434345,
      "grad_norm": 0.059456728398799896,
      "learning_rate": 4.662295081967214e-05,
      "loss": 0.0038,
      "step": 2390
    },
    {
      "epoch": 7.746666666666667,
      "grad_norm": 0.1812104731798172,
      "learning_rate": 4.59672131147541e-05,
      "loss": 0.0036,
      "step": 2400
    },
    {
      "epoch": 7.746666666666667,
      "eval_bleu": 17.91,
      "eval_exact_match": 0.0,
      "eval_loss": 0.025721998885273933,
      "eval_runtime": 20.0962,
      "eval_samples_per_second": 2.488,
      "eval_steps_per_second": 1.244,
      "step": 2400
    },
    {
      "epoch": 7.778989898989899,
      "grad_norm": 0.038729071617126465,
      "learning_rate": 4.531147540983607e-05,
      "loss": 0.0019,
      "step": 2410
    },
    {
      "epoch": 7.811313131313131,
      "grad_norm": 0.046372007578611374,
      "learning_rate": 4.465573770491803e-05,
      "loss": 0.0031,
      "step": 2420
    },
    {
      "epoch": 7.843636363636364,
      "grad_norm": 0.061442140489816666,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0024,
      "step": 2430
    },
    {
      "epoch": 7.875959595959596,
      "grad_norm": 0.04876904934644699,
      "learning_rate": 4.3344262295081966e-05,
      "loss": 0.0029,
      "step": 2440
    },
    {
      "epoch": 7.908282828282828,
      "grad_norm": 0.058647867292165756,
      "learning_rate": 4.268852459016393e-05,
      "loss": 0.0026,
      "step": 2450
    },
    {
      "epoch": 7.908282828282828,
      "eval_bleu": 17.91,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02727542817592621,
      "eval_runtime": 20.239,
      "eval_samples_per_second": 2.47,
      "eval_steps_per_second": 1.235,
      "step": 2450
    },
    {
      "epoch": 7.9406060606060604,
      "grad_norm": 0.15508955717086792,
      "learning_rate": 4.203278688524591e-05,
      "loss": 0.0027,
      "step": 2460
    },
    {
      "epoch": 7.972929292929293,
      "grad_norm": 0.028835877776145935,
      "learning_rate": 4.137704918032787e-05,
      "loss": 0.0028,
      "step": 2470
    },
    {
      "epoch": 8.003232323232323,
      "grad_norm": 0.04506354033946991,
      "learning_rate": 4.072131147540984e-05,
      "loss": 0.0029,
      "step": 2480
    },
    {
      "epoch": 8.035555555555556,
      "grad_norm": 0.044845100492239,
      "learning_rate": 4.00655737704918e-05,
      "loss": 0.002,
      "step": 2490
    },
    {
      "epoch": 8.067878787878788,
      "grad_norm": 0.03710659593343735,
      "learning_rate": 3.9409836065573776e-05,
      "loss": 0.002,
      "step": 2500
    },
    {
      "epoch": 8.067878787878788,
      "eval_bleu": 17.97,
      "eval_exact_match": 0.0,
      "eval_loss": 0.028124965727329254,
      "eval_runtime": 20.1537,
      "eval_samples_per_second": 2.481,
      "eval_steps_per_second": 1.24,
      "step": 2500
    },
    {
      "epoch": 8.10020202020202,
      "grad_norm": 0.061533670872449875,
      "learning_rate": 3.8754098360655736e-05,
      "loss": 0.0016,
      "step": 2510
    },
    {
      "epoch": 8.132525252525253,
      "grad_norm": 0.05527639761567116,
      "learning_rate": 3.809836065573771e-05,
      "loss": 0.0021,
      "step": 2520
    },
    {
      "epoch": 8.164848484848484,
      "grad_norm": 0.03431515395641327,
      "learning_rate": 3.744262295081967e-05,
      "loss": 0.0018,
      "step": 2530
    },
    {
      "epoch": 8.197171717171717,
      "grad_norm": 0.06503644585609436,
      "learning_rate": 3.6786885245901644e-05,
      "loss": 0.002,
      "step": 2540
    },
    {
      "epoch": 8.22949494949495,
      "grad_norm": 0.052258703857660294,
      "learning_rate": 3.6131147540983605e-05,
      "loss": 0.0022,
      "step": 2550
    },
    {
      "epoch": 8.22949494949495,
      "eval_bleu": 17.68,
      "eval_exact_match": 0.0,
      "eval_loss": 0.02936589904129505,
      "eval_runtime": 20.1964,
      "eval_samples_per_second": 2.476,
      "eval_steps_per_second": 1.238,
      "step": 2550
    },
    {
      "epoch": 8.261818181818182,
      "grad_norm": 0.04527921974658966,
      "learning_rate": 3.547540983606558e-05,
      "loss": 0.0018,
      "step": 2560
    },
    {
      "epoch": 8.294141414141414,
      "grad_norm": 0.03674899414181709,
      "learning_rate": 3.481967213114754e-05,
      "loss": 0.0018,
      "step": 2570
    },
    {
      "epoch": 8.326464646464647,
      "grad_norm": 0.035959888249635696,
      "learning_rate": 3.416393442622951e-05,
      "loss": 0.002,
      "step": 2580
    },
    {
      "epoch": 8.35878787878788,
      "grad_norm": 0.07673782855272293,
      "learning_rate": 3.3508196721311473e-05,
      "loss": 0.002,
      "step": 2590
    },
    {
      "epoch": 8.391111111111112,
      "grad_norm": 0.040113337337970734,
      "learning_rate": 3.285245901639345e-05,
      "loss": 0.0015,
      "step": 2600
    },
    {
      "epoch": 8.391111111111112,
      "eval_bleu": 17.79,
      "eval_exact_match": 0.0,
      "eval_loss": 0.029347306117415428,
      "eval_runtime": 20.1938,
      "eval_samples_per_second": 2.476,
      "eval_steps_per_second": 1.238,
      "step": 2600
    },
    {
      "epoch": 8.423434343434343,
      "grad_norm": 0.05487937852740288,
      "learning_rate": 3.2196721311475415e-05,
      "loss": 0.002,
      "step": 2610
    },
    {
      "epoch": 8.455757575757575,
      "grad_norm": 0.0508783720433712,
      "learning_rate": 3.1540983606557375e-05,
      "loss": 0.0019,
      "step": 2620
    },
    {
      "epoch": 8.488080808080808,
      "grad_norm": 0.06091751903295517,
      "learning_rate": 3.088524590163935e-05,
      "loss": 0.0017,
      "step": 2630
    },
    {
      "epoch": 8.52040404040404,
      "grad_norm": 0.023813728243112564,
      "learning_rate": 3.0229508196721313e-05,
      "loss": 0.0016,
      "step": 2640
    },
    {
      "epoch": 8.552727272727273,
      "grad_norm": 0.027598580345511436,
      "learning_rate": 2.9573770491803283e-05,
      "loss": 0.0015,
      "step": 2650
    },
    {
      "epoch": 8.552727272727273,
      "eval_bleu": 17.79,
      "eval_exact_match": 0.0,
      "eval_loss": 0.029040943831205368,
      "eval_runtime": 20.2117,
      "eval_samples_per_second": 2.474,
      "eval_steps_per_second": 1.237,
      "step": 2650
    },
    {
      "epoch": 8.585050505050505,
      "grad_norm": 0.07013873010873795,
      "learning_rate": 2.8918032786885247e-05,
      "loss": 0.0018,
      "step": 2660
    },
    {
      "epoch": 8.617373737373738,
      "grad_norm": 0.06410930305719376,
      "learning_rate": 2.8262295081967217e-05,
      "loss": 0.0017,
      "step": 2670
    },
    {
      "epoch": 8.64969696969697,
      "grad_norm": 0.05965970456600189,
      "learning_rate": 2.760655737704918e-05,
      "loss": 0.0017,
      "step": 2680
    },
    {
      "epoch": 8.682020202020201,
      "grad_norm": 0.0382109098136425,
      "learning_rate": 2.6950819672131152e-05,
      "loss": 0.0017,
      "step": 2690
    },
    {
      "epoch": 8.714343434343434,
      "grad_norm": 0.07121889293193817,
      "learning_rate": 2.6295081967213116e-05,
      "loss": 0.0015,
      "step": 2700
    },
    {
      "epoch": 8.714343434343434,
      "eval_bleu": 17.85,
      "eval_exact_match": 0.0,
      "eval_loss": 0.030126361176371574,
      "eval_runtime": 20.221,
      "eval_samples_per_second": 2.473,
      "eval_steps_per_second": 1.236,
      "step": 2700
    },
    {
      "epoch": 8.746666666666666,
      "grad_norm": 0.03471209108829498,
      "learning_rate": 2.5639344262295083e-05,
      "loss": 0.0013,
      "step": 2710
    },
    {
      "epoch": 8.778989898989899,
      "grad_norm": 0.041204631328582764,
      "learning_rate": 2.498360655737705e-05,
      "loss": 0.0016,
      "step": 2720
    },
    {
      "epoch": 8.811313131313131,
      "grad_norm": 0.06422320008277893,
      "learning_rate": 2.4327868852459017e-05,
      "loss": 0.0018,
      "step": 2730
    },
    {
      "epoch": 8.843636363636364,
      "grad_norm": 0.052103593945503235,
      "learning_rate": 2.3672131147540984e-05,
      "loss": 0.002,
      "step": 2740
    },
    {
      "epoch": 8.875959595959596,
      "grad_norm": 0.06131953373551369,
      "learning_rate": 2.301639344262295e-05,
      "loss": 0.0021,
      "step": 2750
    },
    {
      "epoch": 8.875959595959596,
      "eval_bleu": 17.91,
      "eval_exact_match": 0.0,
      "eval_loss": 0.029997900128364563,
      "eval_runtime": 20.1101,
      "eval_samples_per_second": 2.486,
      "eval_steps_per_second": 1.243,
      "step": 2750
    },
    {
      "epoch": 8.908282828282829,
      "grad_norm": 0.049144476652145386,
      "learning_rate": 2.236065573770492e-05,
      "loss": 0.0012,
      "step": 2760
    },
    {
      "epoch": 8.940606060606061,
      "grad_norm": 0.06839308887720108,
      "learning_rate": 2.1704918032786886e-05,
      "loss": 0.0018,
      "step": 2770
    },
    {
      "epoch": 8.972929292929294,
      "grad_norm": 0.05475727841258049,
      "learning_rate": 2.1049180327868853e-05,
      "loss": 0.0017,
      "step": 2780
    },
    {
      "epoch": 9.003232323232323,
      "grad_norm": 0.025360342115163803,
      "learning_rate": 2.039344262295082e-05,
      "loss": 0.0019,
      "step": 2790
    },
    {
      "epoch": 9.035555555555556,
      "grad_norm": 0.03931573033332825,
      "learning_rate": 1.9737704918032787e-05,
      "loss": 0.0015,
      "step": 2800
    },
    {
      "epoch": 9.035555555555556,
      "eval_bleu": 17.91,
      "eval_exact_match": 0.0,
      "eval_loss": 0.030430443584918976,
      "eval_runtime": 20.2083,
      "eval_samples_per_second": 2.474,
      "eval_steps_per_second": 1.237,
      "step": 2800
    },
    {
      "epoch": 9.067878787878788,
      "grad_norm": 0.031122133135795593,
      "learning_rate": 1.9081967213114754e-05,
      "loss": 0.0014,
      "step": 2810
    },
    {
      "epoch": 9.10020202020202,
      "grad_norm": 0.022892430424690247,
      "learning_rate": 1.842622950819672e-05,
      "loss": 0.0011,
      "step": 2820
    },
    {
      "epoch": 9.132525252525253,
      "grad_norm": 0.043991461396217346,
      "learning_rate": 1.777049180327869e-05,
      "loss": 0.0011,
      "step": 2830
    },
    {
      "epoch": 9.164848484848484,
      "grad_norm": 0.07883622497320175,
      "learning_rate": 1.7114754098360656e-05,
      "loss": 0.0012,
      "step": 2840
    },
    {
      "epoch": 9.197171717171717,
      "grad_norm": 0.03548754006624222,
      "learning_rate": 1.6459016393442626e-05,
      "loss": 0.0013,
      "step": 2850
    },
    {
      "epoch": 9.197171717171717,
      "eval_bleu": 17.91,
      "eval_exact_match": 0.0,
      "eval_loss": 0.031643256545066833,
      "eval_runtime": 20.1507,
      "eval_samples_per_second": 2.481,
      "eval_steps_per_second": 1.241,
      "step": 2850
    },
    {
      "epoch": 9.22949494949495,
      "grad_norm": 0.04381226748228073,
      "learning_rate": 1.5803278688524593e-05,
      "loss": 0.0011,
      "step": 2860
    },
    {
      "epoch": 9.261818181818182,
      "grad_norm": 0.04266715049743652,
      "learning_rate": 1.5147540983606559e-05,
      "loss": 0.0014,
      "step": 2870
    },
    {
      "epoch": 9.294141414141414,
      "grad_norm": 0.01925511285662651,
      "learning_rate": 1.4491803278688526e-05,
      "loss": 0.0016,
      "step": 2880
    },
    {
      "epoch": 9.326464646464647,
      "grad_norm": 0.031047428026795387,
      "learning_rate": 1.3836065573770493e-05,
      "loss": 0.0012,
      "step": 2890
    },
    {
      "epoch": 9.35878787878788,
      "grad_norm": 0.05420690402388573,
      "learning_rate": 1.318032786885246e-05,
      "loss": 0.0013,
      "step": 2900
    },
    {
      "epoch": 9.35878787878788,
      "eval_bleu": 17.85,
      "eval_exact_match": 0.0,
      "eval_loss": 0.031817495822906494,
      "eval_runtime": 20.2017,
      "eval_samples_per_second": 2.475,
      "eval_steps_per_second": 1.238,
      "step": 2900
    },
    {
      "epoch": 9.391111111111112,
      "grad_norm": 0.0408460833132267,
      "learning_rate": 1.2524590163934428e-05,
      "loss": 0.0011,
      "step": 2910
    },
    {
      "epoch": 9.423434343434343,
      "grad_norm": 0.053799018263816833,
      "learning_rate": 1.1868852459016395e-05,
      "loss": 0.0013,
      "step": 2920
    },
    {
      "epoch": 9.455757575757575,
      "grad_norm": 0.04555537551641464,
      "learning_rate": 1.1213114754098362e-05,
      "loss": 0.0012,
      "step": 2930
    },
    {
      "epoch": 9.488080808080808,
      "grad_norm": 0.02647121623158455,
      "learning_rate": 1.0557377049180327e-05,
      "loss": 0.0012,
      "step": 2940
    },
    {
      "epoch": 9.52040404040404,
      "grad_norm": 0.03527582064270973,
      "learning_rate": 9.901639344262295e-06,
      "loss": 0.0011,
      "step": 2950
    },
    {
      "epoch": 9.52040404040404,
      "eval_bleu": 17.85,
      "eval_exact_match": 0.0,
      "eval_loss": 0.032728198915719986,
      "eval_runtime": 20.1812,
      "eval_samples_per_second": 2.478,
      "eval_steps_per_second": 1.239,
      "step": 2950
    },
    {
      "epoch": 9.552727272727273,
      "grad_norm": 0.03503436967730522,
      "learning_rate": 9.245901639344262e-06,
      "loss": 0.0013,
      "step": 2960
    },
    {
      "epoch": 9.585050505050505,
      "grad_norm": 0.03774217888712883,
      "learning_rate": 8.59016393442623e-06,
      "loss": 0.0012,
      "step": 2970
    },
    {
      "epoch": 9.617373737373738,
      "grad_norm": 0.14785611629486084,
      "learning_rate": 7.934426229508198e-06,
      "loss": 0.0013,
      "step": 2980
    },
    {
      "epoch": 9.64969696969697,
      "grad_norm": 0.03427385166287422,
      "learning_rate": 7.278688524590165e-06,
      "loss": 0.0014,
      "step": 2990
    },
    {
      "epoch": 9.682020202020201,
      "grad_norm": 0.04192275553941727,
      "learning_rate": 6.622950819672131e-06,
      "loss": 0.0012,
      "step": 3000
    },
    {
      "epoch": 9.682020202020201,
      "eval_bleu": 17.85,
      "eval_exact_match": 0.0,
      "eval_loss": 0.032205190509557724,
      "eval_runtime": 20.1498,
      "eval_samples_per_second": 2.481,
      "eval_steps_per_second": 1.241,
      "step": 3000
    },
    {
      "epoch": 9.714343434343434,
      "grad_norm": 0.04668525233864784,
      "learning_rate": 5.967213114754098e-06,
      "loss": 0.0015,
      "step": 3010
    },
    {
      "epoch": 9.746666666666666,
      "grad_norm": 0.06136244162917137,
      "learning_rate": 5.3114754098360655e-06,
      "loss": 0.0015,
      "step": 3020
    },
    {
      "epoch": 9.778989898989899,
      "grad_norm": 0.04587635397911072,
      "learning_rate": 4.6557377049180335e-06,
      "loss": 0.0013,
      "step": 3030
    },
    {
      "epoch": 9.811313131313131,
      "grad_norm": 0.02618362568318844,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0011,
      "step": 3040
    },
    {
      "epoch": 9.843636363636364,
      "grad_norm": 0.04300772026181221,
      "learning_rate": 3.3442622950819674e-06,
      "loss": 0.0015,
      "step": 3050
    },
    {
      "epoch": 9.843636363636364,
      "eval_bleu": 17.85,
      "eval_exact_match": 0.0,
      "eval_loss": 0.032413240522146225,
      "eval_runtime": 20.3322,
      "eval_samples_per_second": 2.459,
      "eval_steps_per_second": 1.23,
      "step": 3050
    }
  ],
  "logging_steps": 10,
  "max_steps": 3100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.462247248531292e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
